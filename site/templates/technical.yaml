en:
  tands_tech: '<p><i>Wahrlich es ist nicht das Wissen, sondern das Lernen, nicht das Besitzen, sondern das Erwerben, nicht das Da-Seyn, sondern das Hinkommen, was den grössten Genuss gewährt.</i></p><p>Carl Friedrich Gauss.</p>'
  training: Training
  training_blob: '<p>Given a set of items \( \{ t_i \}, i \in \left[ 0, I \right] \) and a textual embedding \( E: \textrm{text} \rightarrow \mathbb{R}^t \), we use training data in the form of \( l \) runs of preferences. Each run is for the same user (which can be repeated as users can submit multiple runs). A run contains pairs \( (i, p) \) with \( i \in \left[ 0, I \right] \) the item over which the user stated the preference and \( p \in \left\{ -1, 0, 1 \right\} \) the stated preference (positive or negative, 0 means the text was not understood and those tuples are ignored, see the <a href="annotate_$LANG$.html">annotations instructions</a>). Tell-and-Show trains a <a href="https://en.wikipedia.org/wiki/Siamese_neural_network">Siamese Neural Network</a> as follows:</p> <p>Given two tuples \( (i, q), (j, r) \) in the run for the same user such that \( q \neq 0 \wedge r \neq 0 \), then the following network is trained:</p> \[ t_i \rightarrow E \rightarrow \textrm{MLP}_p \rightarrow e_i \] \[ t_j \rightarrow E \rightarrow \textrm{MLP}_p \rightarrow e_j \] then \[ e_i \odot e_j \rightarrow \textrm{output} \] <p>The output is trained against \( q \, \mathrm{xor} \, r \). Only \( \textrm{MLP}_p \) is trained, \( E \) is fixed.</p> <p>The intuition being that when \( r \) and \( s \) are the same, then \( e_i, e_j \) should be close and when they are different, they should be far. What \( \textrm{MLP}_p \) is doing is mapping from the text embedding space to a new, preference embedding space.</p>'
  annotation_schedule: Annotation Schedule
  annotation: '<p>To learn which part of the textual embedding space are preference-carrying, we used <a href="https://en.wikipedia.org/wiki/BIRCH">BIRCH</a> to cluster 5.5 million text descriptions in the English Wikimedia Commons. From there, we kept the 1,000 clusters that have 200 items or more (they account for 27% of all items). For each of the clusters, the item closest to the centroid is computed, we call it the center. Other 4 random items in the cluster are also kept. This constitutes the 5,000 items over which we are <a href="annotate_$LANG$.html">soliciting annotations</a>.</p> <p>The goal of the annotation process is to find as many crossing preferences for texts close enough in embedding space. As such, each time a cluster is selected for a given user, the center and the 4 extra elements are selected for annotation. Finally, there might be areas the preference space that the user likes or dislikes completely, irrespective of the items. To steer away from there, the system selects clusters equidistant from items marked positive and negative, therefore probing the decision boundary for the user.</p> <p>Further detail: for annotation scheduling, the current version uses <a href="about_$LANG$.html">code inherited from an earlier project</a> with <a href="https://github.com/facebookresearch/LASER">LASER embeddings</a> with a dimensionality of 1,024. The target embedding space is 128. For training the Siamese, we use <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf">Universal Sentence Encoders</a> with a text embedding of 128 and same size for preferences embedding.</p>'
  production: Production
  production_blob: '<p>Once the preference metric (the mapping from text to the preference embeddings space) has been trained, all text descriptions of Wikicommons items can be mapped to the preference space, clustered with large clusters and their centers identified. The set of large centers can then be downloaded and a user can annotate their decision boundary over that set. That constitutes their <i>preference profile</i>: a set \( \{ (e, p) \} \) where \( e \) is a preference embedding and \( p \in \{ -1, 1 \} \) (text not understood by the user are ignored).</p>'
  using: 'Using the preference profiles: the Bucket API'
  using_blob: '<p>Instead of retrieving from a server a ranked list of items based on the user''s preferences, the Bucket API returns a random list of 100-1000 items: \( \{ \left( \textrm{text description}, \textrm{preference embedding}, \textrm{URL} \right) \} \), the web browser then used <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">\( k \)-nearest neighbors algorithm</a> to rank the items.</p>'
es:
  training: Entrenamiento
  training_blob: '<p>Dado un conjunto de ítems \( \{ t_i \}, i \in \left[ 0, I \right] \) y un embedding de texto \( E: \textrm{text} \rightarrow \mathbb{R}^t \), usamos los datos de entrenamiento consistentes en \( l \) corridas de preferencias. Cada corrida es de la misma persona (que puede estar duplicada porque la misma persona puede enviar múltiples corridas). Una corrida contiene pares \( (i, p) \) con \( i \in \left[ 0, I \right] \) el ítem sobre el cual la persona ha manifestado su preferencia y \( p \in \left\{ -1, 0, 1 \right\} \) la susodicha preferencia (positiva o negativa, 0 significa que el texto no fue entendido y esas tuplas se ignoran, véanse las <a href="annotate_$LANG$.html">instrucciones de annotación</a> para más detalles). Tell-and-Show entrena una <a href="https://en.wikipedia.org/wiki/Siamese_neural_network">Red Neuronal Siamesa</a> de la siguiente forma:</p> <p>Dadas dos tuplas \( (i, q), (j, r) \) en una corida para la misma persona tales que \( q \neq 0 \wedge r \neq 0 \), entonces la siguiente red neuronal es entrenada:</p> \[ t_i \rightarrow E \rightarrow \textrm{MLP}_p \rightarrow e_i \] \[ t_j \rightarrow E \rightarrow \textrm{MLP}_p \rightarrow e_j \] entonces \[ e_i \odot e_j \rightarrow \textrm{salida} \] <p>La salida se entrena contra \( q \, \mathrm{xor} \, r \). Sólo una \( \textrm{MLP}_p \) se entrena, \( E \) es dado.</p> <p>La intuición es que cuando \( r \) y \( s \) son iguales, entonces \( e_i, e_j \) deben estar cerca y cuando son distintas, deben estar alejados. Lo que la \( \textrm{MLP}_p \) está haciendo es mapeando el espacio de embeddings de texto en un nuevo espacio de embeddings de preferencias.</p>'
  annotation_schedule: Método de Anotación
  annotation: '<p>Para aprender qué parte del espacio de embeddings de texto contiene información pertinente a las preferencias, usamos el algoritmo <a href="https://en.wikipedia.org/wiki/BIRCH">BIRCH</a> para agrupar las 5.5 millones de descripciones textuales en los Commons de Wikimedia en inglés. A partir de ahí, nos quedamos con los 1.000 clusters que tienen 200 ítems o más (ocupan alrededor del 27% de todos los ítems). Para cada uno de esos clusters, identficamos el ítem más cercano al centroide del mismo, al que llamamos el centro del cluster. Otros 4 ítems al azar del cluster han sido seleccionados. Esto constituye unos 5.000 ítems sobre los cuales estamos pidiendo <a href="annotate_$LANG$.html">ayuda para anotar</a>.</p> <p>El objetivo del proceso de anotación es encontrar preferencias cruzadas para textos que son cercanos en el espacio de embedding de textos. De esta forma, cada vez que un cluster ha sido seleccionado para pedirle a alguien que lo anote, le mostramos a la persona el centro y los otros 4 elementos seleccionados. Por último, pueden haber áreas del espacio de preferencias sobre las que la persona que está anotando le gusten todos los ítems o no le guste ningún ítem, más allá del ítem en sí. Para evitar esta situación, el sistema busca de seleccionar para anotación clusters equidistantes de los ítems ya anotados con preferencias positivas y negativas. De esta forma busca elucidar la frontera de decisión de la persona que anota.</p> <p>Más detalles: en este proceso de anotación, la versión actual utiliza <a href="about_$LANG$.html">código fuente heredado de un proyecto anterior</a> que utiliza <a href="https://github.com/facebookresearch/LASER">embeddings del proyecto LASER</a> con una dimensionalidad de 1,024. El espacio objetivo de embedding de preferencias es 128. Para entranar la red siamesa, usamos <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46808.pdf">Universal Sentence Encoders</a> con un tamaño de embeddings de texto de 128 y el mismo tamaño para embeddings de preferencias.</p>'
  production: En Producción
  production_blob: '<p>Una vez que la métrica de preferencias (el mapeo de textos al espacio de embeddings de preferencias) ha sido entrenada, es posible obtener embeddings de preferencias para todos los ítems en Wikipedia Commons, hacer clustering sobre ellos y luego identificar los clusters más grandes con sus respectivos centros. El conjunto de los centros de clusters más grandes puede entonces ser descargado por la gente interesada en usar el sistema y anotar sus fronteras de decisión sobre dicho conjunto de manera privada. Dicha anotación es su <i>perfil de preferencias</i>: un conjunto \( \{ (e, p) \} \) donde \( e \) es un embedding de preferencias y \( p \in \{ -1, 1 \} \) (los textos que no se entiendan simplemente se ignoran).</p>'
  using: 'Usando los perfiles de preferencias: la API Bucket'
  using_blob: '<p>En lugar de que un servidor devuelva un listado de ítems rankeados segun las preferencias de una persona, la API Bucket devuelve una lista al azar de 100 a 1000 ítems: \( \{ \left( \textrm{descriptción textual}, \textrm{embeddings de preferencias}, \textrm{URL} \right) \} \), el navegador web entonces usa <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">el algoritmo de \( k \) vecinos más cercanos</a> para rankear los ítems.</p>'
